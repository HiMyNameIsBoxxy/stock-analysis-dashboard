{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b72a3c",
   "metadata": {},
   "source": [
    "# Incremental ETL Orchestration & Storage Monitoring\n",
    "\n",
    "**What this notebook does**  \n",
    "This notebook orchestrates a daily ETL run over GDELT data, performing for each date:  \n",
    "1. Routing article processing to the correct MongoDB cluster based on date.  \n",
    "2. Invoking `process_articles_for_day` to ingest news into S3 â†’ Mongo pipeline.  \n",
    "3. Logging inserted vs. duplicate counts and elapsed time.  \n",
    "4. Checking MongoDB storage usage per cluster.  \n",
    "5. Halting if the storage limit (512â€¯MB) is approached.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ada792",
   "metadata": {},
   "source": [
    "# 1. Imports & Environment Setup  \n",
    "Import required libraries and load environment variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfeed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from gdelt_loader import process_articles_for_day\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654737b3",
   "metadata": {},
   "source": [
    "# 2. MongoDB Cluster Configuration  \n",
    "Define three dateâ€‘sharded clusters with their connection URIs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2a8384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB cluster configurations\n",
    "CLUSTERS = {\n",
    "    \"cluster1\": {\n",
    "        \"uri\": os.getenv(\"MONGO_ATLAS_URI_1\"),\n",
    "        \"start_date\": \"2024-01-01T00:00:00Z\",\n",
    "        \"end_date\":   \"2024-03-01T23:59:59Z\"\n",
    "    },\n",
    "    \"cluster2\": {\n",
    "        \"uri\": os.getenv(\"MONGO_ATLAS_URI_2\"),\n",
    "        \"start_date\": \"2024-03-02T00:00:00Z\",\n",
    "        \"end_date\":   \"2024-04-26T23:59:59Z\"\n",
    "    },\n",
    "    \"cluster3\": {\n",
    "        \"uri\": os.getenv(\"MONGO_ATLAS_URI_3\"),\n",
    "        \"start_date\": \"2024-04-27T00:00:00Z\",\n",
    "        \"end_date\":   \"2024-06-30T23:59:59Z\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc89346",
   "metadata": {},
   "source": [
    "# 3. Dateâ€‘Based Client Selection  \n",
    "Return the MongoClient for the cluster covering `date_obj`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa80a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client_for_date(date_obj):\n",
    "    \"\"\"Get the appropriate MongoDB client based on the date\"\"\"\n",
    "    for cluster in CLUSTERS.values():\n",
    "        start = datetime.strptime(cluster[\"start_date\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        end   = datetime.strptime(cluster[\"end_date\"],   \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        if start <= date_obj <= end:\n",
    "            return MongoClient(cluster[\"uri\"])\n",
    "    # Default to first cluster\n",
    "    return MongoClient(CLUSTERS[\"cluster1\"][\"uri\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c2c897",
   "metadata": {},
   "source": [
    "# 4. Storage Usage Check  \n",
    "Run `dbstats` against the correct cluster to retrieve current storage size (MB).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d4659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_storage_limit(date_obj):\n",
    "    \"\"\"Check storage limit for the appropriate cluster based on date\"\"\"\n",
    "    client = get_client_for_date(date_obj)\n",
    "    db     = client[\"gdelt_news\"]\n",
    "    stats  = db.command(\"dbstats\")\n",
    "    storage_mb = stats[\"storageSize\"] / (1024 * 1024)\n",
    "    client.close()\n",
    "    return storage_mb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c57d7",
   "metadata": {},
   "source": [
    "# 5. Daily ETL Loop  \n",
    "Iterate from `start_date` to `end_date`, processing each dayâ€™s files, logging results, and checking storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f7e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_articles_for_date_range(bucket, start_date, end_date):\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        date_str = current_date.strftime(\"%Y%m%d\")\n",
    "        print(f\"\\nðŸš€ Processing {date_str}...\")\n",
    "        day_start = time.time()\n",
    "\n",
    "        inserted, duplicates = process_articles_for_day(bucket, date_str)\n",
    "\n",
    "        elapsed = round((time.time() - day_start) / 60, 2)\n",
    "        print(f\"âœ… Finished {date_str}: Inserted {inserted}, Skipped {duplicates}, Time: {elapsed}â€¯min\")\n",
    "\n",
    "        # Append to ETL log\n",
    "        with open(\"etl_log.txt\", \"a\") as log_file:\n",
    "            log_file.write(f\"{date_str}: Inserted={inserted}, Duplicates={duplicates}, Time={elapsed}â€¯min\\n\")\n",
    "\n",
    "        # Monitor storage\n",
    "        storage_mb = check_storage_limit(current_date)\n",
    "        print(f\"ðŸ“¦ MongoDB storage used: {storage_mb:.2f}â€¯MB\")\n",
    "        if storage_mb > 490:\n",
    "            print(\"ðŸ›‘ WARNING: Approaching 512â€¯MB limitâ€”stopping ETL.\")\n",
    "            break\n",
    "\n",
    "        current_date += timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa55438",
   "metadata": {},
   "source": [
    "# 6. Main Execution  \n",
    "Set bucket and date range, then run the ETL loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f20475",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    bucket = \"gdelt-peace-speech\"\n",
    "    start  = datetime.strptime(\"20240111\", \"%Y%m%d\")\n",
    "    end    = datetime.strptime(\"20241031\", \"%Y%m%d\")\n",
    "\n",
    "    load_articles_for_date_range(bucket, start, end)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
