{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4107508b",
   "metadata": {},
   "source": [
    "# Stock Analysis API\n",
    "\n",
    "**What this notebook does**  \n",
    "Weâ€™ll spin up our existing FastAPI app inside a notebook, show how to configure it, and then demo each endpointâ€”querying MongoDB, loading our CSV cache, and visualizing responses inline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65cc194",
   "metadata": {},
   "source": [
    "# 1. Imports & Logging Configuration  \n",
    "Import all necessary packages and set up Pythonâ€™s logging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79254116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException, Query\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import List, Optional, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime, timedelta, date\n",
    "import logging\n",
    "from bson import ObjectId\n",
    "import pytz\n",
    "import pandas as pd\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c88f2a0",
   "metadata": {},
   "source": [
    "# 2. Load environment variables, initialize FastAPI app, and add CORS middleware\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af8885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize FastAPI app\n",
    "app = FastAPI(title=\"Stock Analysis API\")\n",
    "\n",
    "# Add CORS middleware\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Allows all origins\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],  # Allows all methods\n",
    "    allow_headers=[\"*\"],  # Allows all headers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1845cab0",
   "metadata": {},
   "source": [
    "# 3. Default date range  \n",
    "Define the default start and end dates for queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a80a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default date range\n",
    "DEFAULT_START_DATE = \"2024-01-01\"\n",
    "DEFAULT_END_DATE = \"2024-06-12\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9837ea73",
   "metadata": {},
   "source": [
    "# 4. MongoDB connections  \n",
    "Connect to three Atlas clusters and get their `articles` collections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae314b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB connections\n",
    "try:\n",
    "    # First cluster (Jan-Feb)\n",
    "    client1 = MongoClient(os.getenv(\"MONGO_ATLAS_URI_1\"))\n",
    "    db1 = client1[\"stock_analysis\"]\n",
    "    articles1 = db1[\"articles\"]\n",
    "    logger.info(\"Successfully connected to first MongoDB cluster\")\n",
    "    \n",
    "    # Second cluster (Mar-Apr)\n",
    "    client2 = MongoClient(os.getenv(\"MONGO_ATLAS_URI_2\"))\n",
    "    db2 = client2[\"stock_analysis\"]\n",
    "    articles2 = db2[\"articles\"]\n",
    "    logger.info(\"Successfully connected to second MongoDB cluster\")\n",
    "    \n",
    "    # Third cluster (Apr27 onwards)\n",
    "    client3 = MongoClient(os.getenv(\"MONGO_ATLAS_URI_3\"))\n",
    "    db3 = client3[\"stock_analysis\"]\n",
    "    articles3 = db3[\"articles\"]\n",
    "    logger.info(\"Successfully connected to third MongoDB cluster\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error connecting to MongoDB: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2532101",
   "metadata": {},
   "source": [
    "# 5. Load and cache the CSV data  \n",
    "Read in the combined analysis CSV and parse its dates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5641021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and cache the CSV data\n",
    "try:\n",
    "    df = pd.read_csv('combined_analysis_jan_june_2024.csv')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    logger.info(\"Successfully loaded CSV data\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading CSV data: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7829b71",
   "metadata": {},
   "source": [
    "# 6. Pydantic models for request/response  \n",
    "Define schemas for OHLCV, sentiment, companies, heatmap, and time range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5278491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic models for request/response\n",
    "class OHLCVData(BaseModel):\n",
    "    date: str\n",
    "    open: float\n",
    "    high: float\n",
    "    low: float\n",
    "    close: float\n",
    "    volume: float\n",
    "\n",
    "class SentimentData(BaseModel):\n",
    "    date: str\n",
    "    avg_sentiment: float\n",
    "    article_count: int\n",
    "\n",
    "class CompanyData(BaseModel):\n",
    "    company: str\n",
    "    symbol: str\n",
    "    data: List[OHLCVData]\n",
    "\n",
    "class HeatmapData(BaseModel):\n",
    "    date: str\n",
    "    company: str\n",
    "    avg_sentiment: float\n",
    "    article_count: int\n",
    "\n",
    "class TimeRange(BaseModel):\n",
    "    start_date: str\n",
    "    end_date: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba11e7b",
   "metadata": {},
   "source": [
    "# 7. Helper function to get appropriate collection based on date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782536aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get appropriate collection based on date\n",
    "def get_collection_for_date(date_str):\n",
    "    date_obj = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "    if date_obj >= datetime(2024, 4, 27):\n",
    "        return articles3\n",
    "    elif date_obj >= datetime(2024, 3, 2):\n",
    "        return articles2\n",
    "    return articles1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755d20cc",
   "metadata": {},
   "source": [
    "# 8. API Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Endpoints\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"message\": \"Welcome to Stock Analysis API\"}\n",
    "\n",
    "@app.get(\"/companies\")\n",
    "async def get_companies():\n",
    "    \"\"\"Get list of available companies\"\"\"\n",
    "    companies = df[['company', 'symbol']].drop_duplicates().to_dict('records')\n",
    "    return {\"companies\": companies}\n",
    "\n",
    "@app.get(\"/time-range\")\n",
    "async def get_time_range():\n",
    "    \"\"\"Get available date range\"\"\"\n",
    "    return {\n",
    "        \"start_date\": df['date'].min().strftime('%Y-%m-%d'),\n",
    "        \"end_date\": df['date'].max().strftime('%Y-%m-%d'),\n",
    "        \"default_start_date\": DEFAULT_START_DATE,\n",
    "        \"default_end_date\": DEFAULT_END_DATE\n",
    "    }\n",
    "\n",
    "@app.get(\"/ohlcv/{symbol}\")\n",
    "async def get_ohlcv_data(\n",
    "    symbol: str,\n",
    "    start_date: str = Query(DEFAULT_START_DATE, description=\"Start date in YYYY-MM-DD format\"),\n",
    "    end_date: str = Query(DEFAULT_END_DATE, description=\"End date in YYYY-MM-DD format\")\n",
    "):\n",
    "    \"\"\"Get OHLCV data for a specific company\"\"\"\n",
    "    mask = (df['symbol'] == symbol) & (df['date'] >= start_date) & (df['date'] <= end_date)\n",
    "    data = df[mask].sort_values('date')\n",
    "    \n",
    "    if data.empty:\n",
    "        raise HTTPException(status_code=404, detail=f\"No data found for {symbol} in the specified date range\")\n",
    "    \n",
    "    return {\n",
    "        \"company\": data['company'].iloc[0],\n",
    "        \"symbol\": symbol,\n",
    "        \"data\": data[['date', 'open', 'high', 'low', 'close', 'volume']].to_dict('records')\n",
    "    }\n",
    "\n",
    "@app.get(\"/sentiment/{symbol}\")\n",
    "async def get_sentiment_data(\n",
    "    symbol: str,\n",
    "    start_date: str = Query(DEFAULT_START_DATE, description=\"Start date in YYYY-MM-DD format\"),\n",
    "    end_date: str = Query(DEFAULT_END_DATE, description=\"End date in YYYY-MM-DD format\")\n",
    "):\n",
    "    \"\"\"Get sentiment data for a specific company\"\"\"\n",
    "    mask = (df['symbol'] == symbol) & (df['date'] >= start_date) & (df['date'] <= end_date)\n",
    "    data = df[mask].sort_values('date')\n",
    "    \n",
    "    if data.empty:\n",
    "        raise HTTPException(status_code=404, detail=f\"No data found for {symbol} in the specified date range\")\n",
    "    \n",
    "    return {\n",
    "        \"company\": data['company'].iloc[0],\n",
    "        \"symbol\": symbol,\n",
    "        \"data\": data[['date', 'avg_sentiment', 'article_count']].to_dict('records')\n",
    "    }\n",
    "\n",
    "@app.get(\"/heatmap\")\n",
    "async def get_heatmap_data(\n",
    "    start_date: str = Query(DEFAULT_START_DATE, description=\"Start date in YYYY-MM-DD format\"),\n",
    "    end_date: str = Query(DEFAULT_END_DATE, description=\"End date in YYYY-MM-DD format\")\n",
    "):\n",
    "    \"\"\"Get heatmap data for all companies\"\"\"\n",
    "    mask = (df['date'] >= start_date) & (df['date'] <= end_date)\n",
    "    data = df[mask].sort_values(['date', 'company'])\n",
    "    \n",
    "    if data.empty:\n",
    "        raise HTTPException(status_code=404, detail=\"No data found in the specified date range\")\n",
    "    \n",
    "    return {\n",
    "        \"data\": data[['date', 'company', 'avg_sentiment', 'article_count']].to_dict('records')\n",
    "    }\n",
    "\n",
    "@app.get(\"/daily-stats\")\n",
    "async def get_daily_stats(\n",
    "    start_date: str = Query(DEFAULT_START_DATE, description=\"Start date in YYYY-MM-DD format\"),\n",
    "    end_date: str = Query(DEFAULT_END_DATE, description=\"End date in YYYY-MM-DD format\")\n",
    "):\n",
    "    \"\"\"Get daily statistics across all companies\"\"\"\n",
    "    mask = (df['date'] >= start_date) & (df['date'] <= end_date)\n",
    "    daily_stats = df[mask].groupby('date').agg({\n",
    "        'article_count': 'sum',\n",
    "        'avg_sentiment': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    return {\n",
    "        \"data\": daily_stats.to_dict('records')\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b45ba7",
   "metadata": {},
   "source": [
    "# 9. Run the FastAPI Server  \n",
    "If you execute this cell, it will start Uvicorn inside the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2503256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    logger.info(\"Starting FastAPI server...\")\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
